{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages to create absolute file path & make code independent of operating system\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### Import packages for data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "### Import packages to visualize data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### Import packages for feature extraction\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "### Import packages for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "### Import packages for model selection and performance assessment\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, StratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV, learning_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report, precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, mean_squared_error, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/HenriekeMax/Documents/Career_Development/GitHub/FrauenLoop_NLP_Project_2020/src/features\n"
    }
   ],
   "source": [
    "### Read in dataset\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../../data/processed/stackoverflow_preprocessed.csv\").resolve()\n",
    "# Depending on running this in interactive shell vs. terminal, I need to include GitHub/FrauenLoop_NLP_Project_2020 in filepath or not...\n",
    "\n",
    "stackoverflow = pd.read_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackoverflow = pd.read_csv(\"/Users/HenriekeMax/Documents/Career_Development/GitHub/FrauenLoop_NLP_Project_2020/data/processed/stackoverflow_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 29986 entries, 0 to 29999\nData columns (total 15 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   Unnamed: 0            29986 non-null  int64 \n 1   score                 29986 non-null  int64 \n 2   question_title        29986 non-null  object\n 3   question_text         29986 non-null  object\n 4   answer_count          29986 non-null  int64 \n 5   comment_count         29986 non-null  int64 \n 6   creation_date         29986 non-null  object\n 7   tags                  29986 non-null  object\n 8   view_count            29986 non-null  int64 \n 9   answer_text           29986 non-null  object\n 10  score_cat             29986 non-null  int64 \n 11  question_title_clean  29986 non-null  object\n 12  question_text_clean   29986 non-null  object\n 13  tags_clean            29694 non-null  object\n 14  answer_text_clean     29986 non-null  object\ndtypes: int64(6), object(9)\nmemory usage: 3.7+ MB\n"
    }
   ],
   "source": [
    "stackoverflow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop all observations / rows with any missing values\n",
    "\n",
    "stackoverflow = stackoverflow.dropna(how='any', subset=['question_title_clean', 'answer_text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0  score                                     question_title  \\\n0           0      0      How to avoid Bot repeating command in groups?   \n1           1     -3        how to host Asp.net core web application..?   \n2           2      0  discord.ext.commands.errors.MissingRequiredArg...   \n3           3      0                 JPA not saving to DB on WildFly 16   \n4           4      0  Conditionally rendering an array within an arr...   \n\n                                       question_text  answer_count  \\\n0  <p>I created a new Telegram Bot which maintain...             2   \n1  <p>I have more confusion with hosting my appli...             2   \n2  <p>i would like make a command for set permiss...             2   \n3  <p>After migrating from Wildfly-8.2.0 to Wildf...             1   \n4  <p>I've tried many of the methods outlined by ...             1   \n\n   comment_count                     creation_date  \\\n0              0  2019-08-23 14:05:29.463000+00:00   \n1              0  2020-04-27 22:38:03.737000+00:00   \n2              0  2020-02-21 01:10:53.553000+00:00   \n3              1  2019-11-03 23:51:01.683000+00:00   \n4              5  2020-02-23 03:24:42.360000+00:00   \n\n                                            tags  view_count  \\\n0               telegram-bot|python-telegram-bot          79   \n1      asp.net-core|shared-hosting|cloud-hosting          47   \n2                  discord.py|discord.py-rewrite         103   \n3  jpa|jakarta-ee|persistence|jpa-2.1|wildfly-16          22   \n4                        javascript|html|reactjs          40   \n\n                                         answer_text  score_cat  \\\n0  <p>The bot only is replying message, not creat...          0   \n1  <p>If choose their windows cloud hosting platf...          0   \n2  <p>What you're doing right now, is <strong>req...          0   \n3  <p>What was missing is to add the \"eclipselink...          0   \n4  <p>You need to trigger a re-render. This is do...          0   \n\n                                question_title_clean  \\\n0                     avoid bot repeat command group   \n1                  host asp net core web application   \n2  discord ext command error missingrequiredargum...   \n3                                jpa save db wildfly   \n4  conditionally render array within array within...   \n\n                                 question_text_clean  \\\n0  create new telegram bot maintain simple list c...   \n1  confusion host application build application a...   \n2  would like make command set permission text ch...   \n3  migrate wildfly wildfly jee application launch...   \n4  ive try many method outline user dice im sure ...   \n\n                               tags_clean  \\\n0           telegrambot pythontelegrambot   \n1  asp netcore sharedhosting cloudhosting   \n2            discord py discord pyrewrite   \n3   jpa jakartaee persistence jpa wildfly   \n4                 javascript html reactjs   \n\n                                   answer_text_clean  \n0   bot reply message create message use sendmessage  \n1  choose window cloud host platform net core wor...  \n2  right now require guild argument command bot a...  \n3  miss add eclipselink jar file wildfly module s...  \n4  need trigger rerender do call tell content com...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>score</th>\n      <th>question_title</th>\n      <th>question_text</th>\n      <th>answer_count</th>\n      <th>comment_count</th>\n      <th>creation_date</th>\n      <th>tags</th>\n      <th>view_count</th>\n      <th>answer_text</th>\n      <th>score_cat</th>\n      <th>question_title_clean</th>\n      <th>question_text_clean</th>\n      <th>tags_clean</th>\n      <th>answer_text_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>How to avoid Bot repeating command in groups?</td>\n      <td>&lt;p&gt;I created a new Telegram Bot which maintain...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2019-08-23 14:05:29.463000+00:00</td>\n      <td>telegram-bot|python-telegram-bot</td>\n      <td>79</td>\n      <td>&lt;p&gt;The bot only is replying message, not creat...</td>\n      <td>0</td>\n      <td>avoid bot repeat command group</td>\n      <td>create new telegram bot maintain simple list c...</td>\n      <td>telegrambot pythontelegrambot</td>\n      <td>bot reply message create message use sendmessage</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-3</td>\n      <td>how to host Asp.net core web application..?</td>\n      <td>&lt;p&gt;I have more confusion with hosting my appli...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2020-04-27 22:38:03.737000+00:00</td>\n      <td>asp.net-core|shared-hosting|cloud-hosting</td>\n      <td>47</td>\n      <td>&lt;p&gt;If choose their windows cloud hosting platf...</td>\n      <td>0</td>\n      <td>host asp net core web application</td>\n      <td>confusion host application build application a...</td>\n      <td>asp netcore sharedhosting cloudhosting</td>\n      <td>choose window cloud host platform net core wor...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>discord.ext.commands.errors.MissingRequiredArg...</td>\n      <td>&lt;p&gt;i would like make a command for set permiss...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2020-02-21 01:10:53.553000+00:00</td>\n      <td>discord.py|discord.py-rewrite</td>\n      <td>103</td>\n      <td>&lt;p&gt;What you're doing right now, is &lt;strong&gt;req...</td>\n      <td>0</td>\n      <td>discord ext command error missingrequiredargum...</td>\n      <td>would like make command set permission text ch...</td>\n      <td>discord py discord pyrewrite</td>\n      <td>right now require guild argument command bot a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>JPA not saving to DB on WildFly 16</td>\n      <td>&lt;p&gt;After migrating from Wildfly-8.2.0 to Wildf...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2019-11-03 23:51:01.683000+00:00</td>\n      <td>jpa|jakarta-ee|persistence|jpa-2.1|wildfly-16</td>\n      <td>22</td>\n      <td>&lt;p&gt;What was missing is to add the \"eclipselink...</td>\n      <td>0</td>\n      <td>jpa save db wildfly</td>\n      <td>migrate wildfly wildfly jee application launch...</td>\n      <td>jpa jakartaee persistence jpa wildfly</td>\n      <td>miss add eclipselink jar file wildfly module s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>Conditionally rendering an array within an arr...</td>\n      <td>&lt;p&gt;I've tried many of the methods outlined by ...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2020-02-23 03:24:42.360000+00:00</td>\n      <td>javascript|html|reactjs</td>\n      <td>40</td>\n      <td>&lt;p&gt;You need to trigger a re-render. This is do...</td>\n      <td>0</td>\n      <td>conditionally render array within array within...</td>\n      <td>ive try many method outline user dice im sure ...</td>\n      <td>javascript html reactjs</td>\n      <td>need trigger rerender do call tell content com...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "### Print out dataset for overview\n",
    "\n",
    "stackoverflow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count number of words in an answer\n",
    "\n",
    "class WordCounter(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        pass\n",
    "\n",
    "    def transform(self, df):\n",
    "        ### Variable name to compute number of words on\n",
    "        name = df.columns\n",
    "        ### Make into list\n",
    "        answer_list = df[name[0]].tolist()\n",
    "        ### Compute number of words for each answer\n",
    "        wordcount = [len(re.findall(r'\\w+', str(answer))) for answer in answer_list]\n",
    "        ### Make into a pandas df\n",
    "        df_new = pd.DataFrame(wordcount)\n",
    "        ### Add suffix\n",
    "        df_new = df_new.add_suffix(name)\n",
    "        return df_new\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        ### Unless error returns self\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0Index(['answer_text_clean'], dtype='object')\n0                                              7\n1                                             22\n2                                             92\n3                                             34\n4                                             82",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0Index(['answer_text_clean'], dtype='object')</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "### Check if WordCounter class works as desired\n",
    "\n",
    "wordcounter = WordCounter(stackoverflow[['answer_text_clean']])\n",
    "stackoverflow_new = wordcounter.transform(stackoverflow[['answer_text_clean']])\n",
    "stackoverflow_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determining whether or not answer contains code\n",
    "\n",
    "class CodeCheck(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, df):\n",
    "        ### Check if answer contains code or not\n",
    "        df_new = df[['answer_text']].copy()\n",
    "        df_new['code_binary'] = df_new['answer_text'].str.contains('<code>', regex=False)*1      \n",
    "        ### Drop text\n",
    "        df_new = df_new.drop(columns = ['answer_text'], axis = 1)\n",
    "        return df_new\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        ### Unless error returns self\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    24144\n0     5550\nName: code_binary, dtype: int64"
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "### Check if CodeCheck class works as desired\n",
    "\n",
    "codecheck = CodeCheck(stackoverflow) \n",
    "stackover_new = codecheck.transform(stackoverflow)\n",
    "\n",
    "### Check of possible patterns in code existence and answer score\n",
    "\n",
    "stack_new['code_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determining whether or not answer contains code\n",
    "\n",
    "class CodeCounter(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, df):\n",
    "        ### Check if answer contains code or not\n",
    "        df_new = df[['answer_text']].copy()\n",
    "        df_new['code_count'] = df_new['answer_text'].str.count('<code>')     \n",
    "        ### Drop text\n",
    "        df_new = df_new.drop(columns = ['answer_text'], axis = 1)\n",
    "        return df_new\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        ### Unless error returns self\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   code_count\n0           0\n1           0\n2           4\n3           0\n4           7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "### Check if CodeCheck class works as desired\n",
    "\n",
    "codecount = CodeCounter(stackoverflow) \n",
    "stackover_new = codecount.transform(stackoverflow)\n",
    "\n",
    "stackover_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      5573\n1      8795\n2      5187\n3      3087\n4      1994\n       ... \n80        1\n85        1\n88        1\n101       1\n102       1\nName: code_count, Length: 61, dtype: int64"
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "### Check distribution of code counts\n",
    "\n",
    "stackover_new['code_count'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute n grams from a dataframe for a given variable\n",
    "\n",
    "class Ngrams(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        pass\n",
    "\n",
    "    def transform(self, df):\n",
    "        ### Save name of variable to analyze\n",
    "        name = df.columns\n",
    "        #### Initiate TfidfVectorizer\n",
    "        vectorizer = TfidfVectorizer(strip_accents = 'unicode', use_idf = True, \\\n",
    "                                     stop_words = 'english', analyzer = 'word', \\\n",
    "                                     ngram_range = (1, 1) , max_features = 300)\n",
    "\n",
    "        ### Fit to data\n",
    "        X_train = vectorizer.fit_transform(df[name[0]].values.astype(str))\n",
    "        # X_train = X_train.toarray()\n",
    "        # is this needed? how do I address mismatching shape problem\n",
    "\n",
    "        ### Return sparse matrix\n",
    "        return X_train\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        ### Unless error returns self\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 284)\t0.18668056133161562\n  (0, 62)\t0.32526564334220925\n  (0, 171)\t0.9270127449404844\n  (1, 265)\t0.5808322803582754\n  (1, 231)\t0.45184055316117894\n  (1, 298)\t0.35818577823349645\n  (1, 296)\t0.5746102373644851\n  (2, 137)\t0.1084195698364375\n  (2, 89)\t0.13026371620718574\n  (2, 122)\t0.30887861748849305\n  (2, 108)\t0.0810824222277791\n  (2, 195)\t0.2614231922161136\n  (2, 22)\t0.2992936152564825\n  (2, 69)\t0.24241722218621634\n  (2, 239)\t0.13587661388280617\n  (2, 247)\t0.19341495682494572\n  (2, 79)\t0.12938860119583803\n  (2, 294)\t0.09225096235418555\n  (2, 200)\t0.1255211188324691\n  (2, 184)\t0.09890953079283116\n  (2, 262)\t0.09015166538768556\n  (2, 58)\t0.12912467053591078\n  (2, 159)\t0.09986626258867055\n  (2, 3)\t0.12765289393425364\n  (2, 45)\t0.5698260280507296\n  :\t:\n  (29983, 4)\t0.1375946298046813\n  (29983, 284)\t0.08630375651032202\n  (29984, 142)\t0.2865915490787619\n  (29984, 105)\t0.1441529020330205\n  (29984, 196)\t0.2692668444143726\n  (29984, 222)\t0.1408519561941906\n  (29984, 21)\t0.15569793420222822\n  (29984, 291)\t0.28033002157563974\n  (29984, 237)\t0.2369169634523472\n  (29984, 141)\t0.30627001692149586\n  (29984, 226)\t0.2326580658554976\n  (29984, 287)\t0.09363333386458393\n  (29984, 43)\t0.41692583133289723\n  (29984, 19)\t0.12350431396936683\n  (29984, 243)\t0.1353647730963164\n  (29984, 150)\t0.08864620828001937\n  (29984, 260)\t0.14548243214402412\n  (29984, 177)\t0.08810388180825508\n  (29984, 122)\t0.47220508039252207\n  (29984, 58)\t0.14805166652561952\n  (29985, 287)\t0.38450351561187646\n  (29985, 114)\t0.3610383359062196\n  (29985, 177)\t0.36179692526296725\n  (29985, 45)\t0.536594454835074\n  (29985, 224)\t0.5504341399283732\n"
    }
   ],
   "source": [
    "ngrams = Ngrams(stackoverflow['answer_text_clean'])\n",
    "\n",
    "stackover_new = ngrams.transform(stackoverflow[['answer_text_clean']])\n",
    "\n",
    "print(stackover_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split into predictors and outcome data\n",
    "\n",
    "y = stackoverflow['score_cat']\n",
    "# y = label_binarize(y, classes=[0, 1, 2]) --> to accommodate roc\n",
    "X = stackoverflow.drop(['score_cat', 'score', 'answer_count', 'comment_count', 'creation_date', 'view_count'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split into train and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model selection process: Create list of different classifiers/algorithms to try out\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(random_state=1),\n",
    "    DecisionTreeClassifier(random_state=1),\n",
    "    RandomForestClassifier(random_state=1),\n",
    "    GradientBoostingClassifier(random_state=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "KNeighborsClassifier()\n              precision    recall  f1-score   support\n\n           0       0.34      1.00      0.51      3056\n           1       0.90      0.03      0.06      3007\n           2       0.00      0.00      0.00      2933\n\n    accuracy                           0.35      8996\n   macro avg       0.41      0.34      0.19      8996\nweighted avg       0.42      0.35      0.19      8996\n\nSVC(random_state=1)\n              precision    recall  f1-score   support\n\n           0       0.80      0.03      0.05      3056\n           1       0.92      0.03      0.06      3007\n           2       0.33      1.00      0.50      2933\n\n    accuracy                           0.34      8996\n   macro avg       0.69      0.35      0.20      8996\nweighted avg       0.69      0.34      0.20      8996\n\nDecisionTreeClassifier(random_state=1)\n              precision    recall  f1-score   support\n\n           0       0.80      0.03      0.05      3056\n           1       0.92      0.03      0.06      3007\n           2       0.33      1.00      0.50      2933\n\n    accuracy                           0.34      8996\n   macro avg       0.69      0.35      0.20      8996\nweighted avg       0.69      0.34      0.20      8996\n\nRandomForestClassifier(random_state=1)\n              precision    recall  f1-score   support\n\n           0       0.80      0.03      0.05      3056\n           1       0.92      0.03      0.06      3007\n           2       0.33      1.00      0.50      2933\n\n    accuracy                           0.34      8996\n   macro avg       0.69      0.35      0.20      8996\nweighted avg       0.69      0.34      0.20      8996\n\nGradientBoostingClassifier(random_state=1)\n              precision    recall  f1-score   support\n\n           0       0.80      0.03      0.05      3056\n           1       0.92      0.03      0.06      3007\n           2       0.33      1.00      0.50      2933\n\n    accuracy                           0.34      8996\n   macro avg       0.69      0.35      0.20      8996\nweighted avg       0.69      0.34      0.20      8996\n\n"
    }
   ],
   "source": [
    "### Model selection process: Loop through the different classifiers using the pipeline\n",
    "\n",
    "for classifier in classifiers:\n",
    "    model_pipeline = Pipeline([\n",
    "        ('feats', FeatureUnion([\n",
    "            # Ngrams\n",
    "            ('ngram', Ngrams(X_train[['answer_text_clean']]))\n",
    "            # Wordcounter\n",
    "            # ('wordcount', WordCounter(X_train[['answer_text_clean']]))\n",
    "            # Code contained\n",
    "            # ('codecheck', CodeCheck(X_train)),\n",
    "            # No. of code snippets\n",
    "            # ('codecounter', CodeCounter(X_train))\n",
    "            ])),\n",
    "            # Classifier\n",
    "            ('classifier', classifier)])\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    y_predict = model_pipeline.predict(X_test)\n",
    "    print(classifier)\n",
    "    print(metrics.classification_report(y_test, y_predict))\n",
    "\n",
    "    # map predictions on to dataframe, then create a column if prediction correct and understand false predictions\n",
    "    # which samples from great answers have been predicted bad\n",
    "    # which samples from bad answers have been predicted great?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiate classifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the model cross-validation configuration\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'classifier__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'classifier__max_features': ['auto', 'sqrt'], 'classifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'classifier__min_samples_split': [2, 5, 10], 'classifier__min_samples_leaf': [1, 2, 4]}\n"
    }
   ],
   "source": [
    "### Choose best-performing model to tune using random hyperparameter grid\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "### Create random grid\n",
    "random_grid = {'classifier__n_estimators': n_estimators,\n",
    "               'classifier__max_features': max_features,\n",
    "               'classifier__max_depth': max_depth,\n",
    "               'classifier__min_samples_split': min_samples_split,\n",
    "               'classifier__min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 32.9min\n[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 74.2min\n[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 166.2min\n[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 239.8min finished\n{'classifier__n_estimators': 2000, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': None}\n0.37238393071926873\n"
    }
   ],
   "source": [
    "### Find best combination of parameters using randomized hyperparameter search\n",
    "\n",
    "random_grid_classifier = RandomizedSearchCV(model_pipeline, param_distributions = random_grid, n_iter = 100, cv = cv, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "random_grid_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(random_grid_classifier.best_params_)\n",
    "\n",
    "print(random_grid_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GradientBoostingClassifier(random_state=1)\n              precision    recall  f1-score   support\n\n           0       0.80      0.03      0.05      3056\n           1       0.92      0.03      0.06      3007\n           2       0.33      1.00      0.50      2933\n\n    accuracy                           0.34      8996\n   macro avg       0.69      0.35      0.20      8996\nweighted avg       0.69      0.34      0.20      8996\n\n"
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('feats', FeatureUnion([\n",
    "        # Ngrams\n",
    "        ('ngram', Ngrams(X_train[['answer_text_clean']]))\n",
    "        # Wordcounter\n",
    "        # ('wordcount', WordCounter(X_train[['answer_text_clean']]))\n",
    "        # Code contained\n",
    "        # ('codecheck', CodeCheck(X_train)),\n",
    "        # No. of code snippets\n",
    "        # ('codecounter', CodeCounter(X_train))\n",
    "        ])),\n",
    "        # Classifier\n",
    "        ('classifier', classifier)])\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_predict = model_pipeline.predict(X_test)\n",
    "print(classifier)\n",
    "print(metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'classifier__n_estimators': [1000, 2000, 3000, 4000], 'classifier__max_features': ['sqrt'], 'classifier__max_depth': [None, 10, 20], 'classifier__min_samples_split': [1, 2, 3, 4], 'classifier__min_samples_leaf': [1, 2, 3]}\n"
    }
   ],
   "source": [
    "### Create param grid based on results from random grid search\n",
    "\n",
    "param_grid = {'classifier__n_estimators': [1000, 2000, 3000, 4000],\n",
    "               'classifier__max_features': ['sqrt'],\n",
    "               'classifier__max_depth': [None, 10, 20],\n",
    "               'classifier__min_samples_split': [1, 2, 3, 4],\n",
    "               'classifier__min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose best-performing model to tune using GridSearchCV\n",
    "\n",
    "grid_classifier = GridSearchCV(model_pipeline, param_grid = param_grid, cv=cv, iid=False, n_jobs=-1, refit = True)\n",
    "# scoring='roc_auc' --> reincorporate\n",
    "grid_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best result: %f using parameters %s\" % (grid_classifier.best_score_, grid_classifier.best_params_))\n",
    "\n",
    "### Assess model performance on test data\n",
    "print(\"Model Score assessed on test data: %.3f\" % grid_classifier.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification Report:\", classification_report(y_test, grid_classifier.predict(X_test)))\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define classifier with tuned parameters and model pipline\n",
    "\n",
    "classifier = GradientBoostingClassifier(max_depth = 10, \n",
    "                                        max_features = 'auto', \n",
    "                                        min_samples_leaf = 5,\n",
    "                                        min_samples_split = 3, \n",
    "                                        n_estimators = 200, \n",
    "                                        random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fitting pipeline to train data\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "### Assess model performance on test data\n",
    "\n",
    "print(\"model score: %.3f\" % model_pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "\n",
    "  # confm_hold = confusion_matrix(y_test, y_predict)\n",
    "    # print(confm_hold)\n",
    "\n",
    "# np.array(s)\n",
    "## confm_hold_df = pd.DataFrame(confm_hold, index = ['No Medal', 'Medal'],\n",
    "                               # columns = ['No Medal', 'Medal'])\n",
    "## plt.figure(figsize=(5,4))\n",
    "## sns.heatmap(confm_hold_df, annot=True, fmt=\".4f\", linewidths=.5, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipe different features in with a name so the step can be later called for details\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('feats', FeatureUnion([\n",
    "        # Ngrams\n",
    "        ('ngram_all', Ngrams(X_train[['answer_text_clean']]))\n",
    "    ])),\n",
    "     # Classifier\n",
    "     ('kneighbors', KNeighborsClassifier(n_neighbors=5, leaf_size=40))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross validation and tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'kneighbors__n_neighbors': (3, 5, 10),\n",
    "            'kneighbors__leaf_size': (10, 20 , 30),\n",
    "            'kneighbors__p': (1,2)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find best model\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, iid=False, n_jobs=-1, refit = True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print best model\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "\n",
    "print(classification_report(y_test, grid_search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To Do\n",
    "\n",
    "# Finalize cleaner function (whitespaces etc.)\n",
    "# Additional features, e.g.\n",
    "    ### Figure out no. of switches from code to explanation\n",
    "    ### Extract tags into separate columns and one-hot-encode\n",
    "\n",
    "# Play with different ngram (1,2,3) and max feature numbers\n",
    "# Incorporate functions/call them in pipeline\n",
    "# Try out different models\n",
    "# Hypertune model\n",
    "\n",
    "\n",
    "# Add cross validation\n",
    "# Look at mispredictions to make more targeted features\n",
    "# Make those features\n",
    "# Model and you can also try additional types of models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitstackconda62acee1f2fa049ee9302fd58619215ba",
   "display_name": "Python 3.8.0 64-bit ('stack': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}