{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages for authentication\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "### Import packages for converting query results into dataframe\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "## Import packages to create absolute file path &  make code independent of operating system\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "### Import packages to visualize data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Authentication \n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/GoogleBigQuery_key.json\").resolve()\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct a BigQuery client object.\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, \n",
    "project = credentials.project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Getting overview of Stackoverflow tables\n",
    "\n",
    "stackoverflow = client.dataset('stackoverflow', project= 'bigquery-public-data')\n",
    "print([x.table_id for x in client.list_tables(stackoverflow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make an API request\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "      pq.score as question_score, pa.score as answer_score, pq.id as question_id, pa.parent_id as question_id_check, pq.title as question_title, pq.body       as question_text, pq.answer_count, pq.comment_count, pq.creation_date, pq.tags, pq.view_count, pa.body as answer_text\n",
    "FROM `bigquery-public-data.stackoverflow.posts_questions` pq\n",
    "INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` pa ON pq.id = pa.parent_id\n",
    "WHERE pa.creation_date > \"2019-05-30 00:00:00.000 UTC\"\n",
    "\"\"\"\n",
    "\n",
    "dataframe = (\n",
    "    client.query(query)\n",
    "    .result()\n",
    "    .to_dataframe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe to a csv file\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw.csv\").resolve()\n",
    "\n",
    "dataframe.to_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporary code to quickly open dataset\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw.csv\").resolve()\n",
    "\n",
    "dataframe = pd.read_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Display query results\n",
    "\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for null values\n",
    "\n",
    "dataframe.isnull().values.any()\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Histogram of distribution of the answer scores\n",
    "\n",
    "f, ax = plt.subplots(figsize=(40,40))\n",
    "sns.countplot(x='answer_score', data=dataframe)\n",
    "plt.xlim(None, 100) \n",
    "plt.ylim(0, 9000) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Histogram of distribution of the number of views of the question & answer\n",
    "\n",
    "f, ax = plt.subplots(figsize=(40,40))\n",
    "sns.countplot(x='view_count', data=dataframe)\n",
    "plt.xlim(None, 200) \n",
    "plt.ylim(0, None) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarization of variables for only numeric\n",
    "\n",
    "dataframe.describe()\n",
    "\n",
    "# mean score is 0.83 while 50% percentile / median score is 0.\n",
    "# 25th percentile for view count is 39 views, median is 64 views;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['answer_score'].value_counts() # .sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop all datarows with answers that have gotten fewer than 39 views (25th percentile in view_count distribution)\n",
    "\n",
    "dataframe_views = dataframe.drop(dataframe[dataframe.view_count < 39].index)\n",
    "len(dataframe_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe with only > 39 views to a csv file\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw_views.csv\").resolve()\n",
    "\n",
    "dataframe_views.to_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign category (bad, good, great) for score\n",
    "\n",
    "score_bucketing_all = lambda x: 'bad' if x < 0 else 'good' if (x >= 1 and x <= 6) else 'great' if x >= 7 else None\n",
    "\n",
    "dataframe_views['score_cat_all'] = dataframe_views['answer_score'].apply(score_bucketing_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"{} unique values in column\".format('score_cat_all'))\n",
    "print(\"{}\".format(dataframe_views['score_cat_all'].unique()),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign category (good, great) for score; ignore negative and zero scores\n",
    "\n",
    "score_bucketing_positive = lambda x: 'good' if (x >= 1 and x <= 6) else 'great' if x >= 7 else None\n",
    "\n",
    "dataframe_views['score_cat_positive'] = dataframe_views['answer_score'].apply(score_bucketing_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"{} unique values in column\".format('score_cat_positive'))\n",
    "print(\"{}\".format(dataframe_views['score_cat_positive'].unique()),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Look at the data to understand the type and missing values\n",
    "\n",
    "print(dataframe_views.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataframe_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample equal amounts of data rows for \"bad\", \"good\" and \"great\" answers from main dataset\n",
    "\n",
    "dataframe_sampled_all = dataframe_views.groupby('score_cat_all', group_keys=False).apply(lambda x: x.sample(n=13000, random_state = 1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if equal sampling of \"bad\", \"good\", and \"great\" answers was successful\n",
    "\n",
    "dataframe_sampled_all.score_cat_all.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe to a csv file\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw_views_sampled_all.csv\").resolve()\n",
    "\n",
    "dataframe_sampled_all.to_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample only one answer randomly per stackoverflow question\n",
    "\n",
    "df_all_final = dataframe_sampled_all.groupby('question_id', group_keys=False).apply(lambda x: x.sample(n = 1, random_state = 1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample equal amounts of data rows for \"bad\", \"good\" and \"great\" answers from main dataset\n",
    "\n",
    "df_all_final = df_all_final.groupby('score_cat_all', group_keys=False).apply(lambda x: x.sample(n=10000, random_state = 1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if classes \"bad\", \"good\", and \"great\" are still roughly balanced\n",
    "\n",
    "df_all_final.score_cat_all.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save sample of dataframe to a csv file\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw_finalsample_all.csv\").resolve()\n",
    "df_all_final.to_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample equal amounts of data rows for \"good\" and \"great\" answers from main dataset\n",
    "\n",
    "dataframe_sampled_positive = dataframe_views.groupby('score_cat_positive', group_keys=False).apply(lambda x: x.sample(n=18000, random_state = 1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if equal sampling of classes \"good\" and \"great\" was successful\n",
    "\n",
    "dataframe_sampled_positive.score_cat_positive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe to a csv file\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw_views_sampled_positive.csv\").resolve()\n",
    "\n",
    "dataframe_sampled_positive.to_csv(os.path.join(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample only one answer randomly per stackoverflow question\n",
    "\n",
    "df_positive_final = dataframe_sampled_positive.groupby('question_id', group_keys=False).apply(lambda x: x.sample(n = 1, random_state = 1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample equal amounts of data rows for \"good\" and \"great\" answers from main dataset\n",
    "\n",
    "df_positive_final = df_positive_final.groupby('score_cat_positive', group_keys=False).apply(lambda x: x.sample(n=15000, random_state = 1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if classses \"good\" and \"great\" are still roughly balanced\n",
    "\n",
    "df_positive_final.score_cat_positive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe to a csv file\n",
    "\n",
    "base_path = Path(\"__file__\").parent\n",
    "full_path = (base_path / \"../data/raw/stackoverflow_raw_finalsample_positive.csv\").resolve()\n",
    "\n",
    "df_positive_final.to_csv(os.path.join(full_path))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitstackconda62acee1f2fa049ee9302fd58619215ba",
   "display_name": "Python 3.8.0 64-bit ('stack': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}